{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33a175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import yaml\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, \\\n",
    "                            recall_score, f1_score, log_loss, precision_recall_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import optuna\n",
    "\n",
    "from typing import Tuple, Set\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RAND=42\n",
    "\n",
    "N_FOLDS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea7ef03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fec7cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(string):\n",
    "    return list(map(float, string[1:-1].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2075059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred, y_score, name = \"Default\"):\n",
    "    \"\"\"Метрики для задачи классификации\"\"\"\n",
    "    df_metrics = pd.DataFrame()\n",
    "\n",
    "    df_metrics['model'] = [name]\n",
    "    df_metrics['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    df_metrics['ROC_AUC'] = roc_auc_score(y_test, y_score[:, 1])\n",
    "    df_metrics['Precision'] = precision_score(y_test, y_pred, zero_division=0)\n",
    "    df_metrics['Recall'] = recall_score(y_test, y_pred, zero_division=0)\n",
    "    df_metrics['f1'] = f1_score(y_test, y_pred, zero_division=0)\n",
    "    df_metrics['Logloss'] = log_loss(y_test, y_score)\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0f8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"../config/params.yaml\"\n",
    "config = yaml.load(open(config_path), Loader=yaml.FullLoader)\n",
    "\n",
    "preproc = config[\"preprocessing\"]\n",
    "train = config[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127dd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_model = \"../config/model_params/lightgbm.yaml\"\n",
    "\n",
    "model_params = yaml.load(open(config_path), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59358de",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5623d75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase</th>\n",
       "      <th>forsmallbiz</th>\n",
       "      <th>price</th>\n",
       "      <th>customer</th>\n",
       "      <th>supplier</th>\n",
       "      <th>is_winner</th>\n",
       "      <th>vectorized_tokens</th>\n",
       "      <th>month</th>\n",
       "      <th>reg_code</th>\n",
       "      <th>purchase_size</th>\n",
       "      <th>flag_won</th>\n",
       "      <th>n_unique_okpd2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>290000.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.18815488  0.1963165   0.08348706  0.132998...</td>\n",
       "      <td>2</td>\n",
       "      <td>58.2_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2834</td>\n",
       "      <td>1</td>\n",
       "      <td>105000.00</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 1.88778124e-01  1.99460707e-01  8.44090815e-...</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154949</td>\n",
       "      <td>1</td>\n",
       "      <td>98967.50</td>\n",
       "      <td>11235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.17555872  0.0838882   0.01939559  0.047119...</td>\n",
       "      <td>2</td>\n",
       "      <td>63.9_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147950</td>\n",
       "      <td>0</td>\n",
       "      <td>77460.03</td>\n",
       "      <td>11061</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 2.09548737e-01  1.98348963e-01  3.00821184e-...</td>\n",
       "      <td>3</td>\n",
       "      <td>62.0_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165990</td>\n",
       "      <td>0</td>\n",
       "      <td>138000.00</td>\n",
       "      <td>11558</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 1.55703006e-01  1.47389050e-01  4.36386056e-...</td>\n",
       "      <td>3</td>\n",
       "      <td>62.0_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       purchase  forsmallbiz      price  customer  supplier  is_winner  \\\n",
       "index                                                                    \n",
       "0             3            1  290000.00         2         1          1   \n",
       "1          2834            1  105000.00       218         1          1   \n",
       "2        154949            1   98967.50     11235         1          1   \n",
       "3        147950            0   77460.03     11061         1          1   \n",
       "4        165990            0  138000.00     11558         1          1   \n",
       "\n",
       "                                       vectorized_tokens  month reg_code  \\\n",
       "index                                                                      \n",
       "0      [ 0.18815488  0.1963165   0.08348706  0.132998...      2   58.2_2   \n",
       "1      [ 1.88778124e-01  1.99460707e-01  8.44090815e-...      2   62.0_2   \n",
       "2      [ 0.17555872  0.0838882   0.01939559  0.047119...      2   63.9_2   \n",
       "3      [ 2.09548737e-01  1.98348963e-01  3.00821184e-...      3   62.0_2   \n",
       "4      [ 1.55703006e-01  1.47389050e-01  4.36386056e-...      3   62.0_2   \n",
       "\n",
       "       purchase_size  flag_won  n_unique_okpd2  \n",
       "index                                           \n",
       "0                  1       0.0               4  \n",
       "1                  1       0.0               4  \n",
       "2                  1       0.0               4  \n",
       "3                  1       0.0               4  \n",
       "4                  1       0.0               4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(preproc['train_data'])\n",
    "df_train = df_train.set_index('index')\n",
    "\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f2e6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase</th>\n",
       "      <th>forsmallbiz</th>\n",
       "      <th>price</th>\n",
       "      <th>customer</th>\n",
       "      <th>supplier</th>\n",
       "      <th>is_winner</th>\n",
       "      <th>vectorized_tokens</th>\n",
       "      <th>month</th>\n",
       "      <th>reg_code</th>\n",
       "      <th>purchase_size</th>\n",
       "      <th>flag_won</th>\n",
       "      <th>n_unique_okpd2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1064</td>\n",
       "      <td>1</td>\n",
       "      <td>181720.00</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 1.77900028e-01  8.02768195e-02  1.25833983e-...</td>\n",
       "      <td>11</td>\n",
       "      <td>58.2_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1729</td>\n",
       "      <td>1</td>\n",
       "      <td>167448.00</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 2.70711475e-01  8.42926477e-02  4.42017172e-...</td>\n",
       "      <td>12</td>\n",
       "      <td>62.0_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2430</td>\n",
       "      <td>1</td>\n",
       "      <td>200248.16</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 2.59523023e-01  1.20019309e-01  7.98608701e-...</td>\n",
       "      <td>12</td>\n",
       "      <td>62.0_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156898</td>\n",
       "      <td>0</td>\n",
       "      <td>190740.00</td>\n",
       "      <td>11266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.20131386  0.07292083 -0.01833528 -0.017387...</td>\n",
       "      <td>12</td>\n",
       "      <td>62.0_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412017</td>\n",
       "      <td>1</td>\n",
       "      <td>2886156.00</td>\n",
       "      <td>9651</td>\n",
       "      <td>100009</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 5.40626203e-02  7.06050537e-02 -3.14055514e-...</td>\n",
       "      <td>11</td>\n",
       "      <td>27.4_77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       purchase  forsmallbiz       price  customer  supplier  is_winner  \\\n",
       "index                                                                     \n",
       "0          1064            1   181720.00        70         1          1   \n",
       "1          1729            1   167448.00       105         1          1   \n",
       "2          2430            1   200248.16       201         1          1   \n",
       "3        156898            0   190740.00     11266         1          1   \n",
       "4        412017            1  2886156.00      9651    100009          0   \n",
       "\n",
       "                                       vectorized_tokens  month reg_code  \\\n",
       "index                                                                      \n",
       "0      [ 1.77900028e-01  8.02768195e-02  1.25833983e-...     11   58.2_2   \n",
       "1      [ 2.70711475e-01  8.42926477e-02  4.42017172e-...     12   62.0_2   \n",
       "2      [ 2.59523023e-01  1.20019309e-01  7.98608701e-...     12   62.0_2   \n",
       "3      [ 0.20131386  0.07292083 -0.01833528 -0.017387...     12   62.0_2   \n",
       "4      [ 5.40626203e-02  7.06050537e-02 -3.14055514e-...     11  27.4_77   \n",
       "\n",
       "       purchase_size  flag_won  n_unique_okpd2  \n",
       "index                                           \n",
       "0                  1       0.0             4.0  \n",
       "1                  1       0.0             4.0  \n",
       "2                  1       0.0             4.0  \n",
       "3                  1       0.0             4.0  \n",
       "4                  1       0.0             1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(preproc['test_data'])\n",
    "df_test = df_test.set_index('index')\n",
    "\n",
    "df_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634c6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['vectorized_tokens'] = df_train['vectorized_tokens'].apply(extract_words)\n",
    "df_test['vectorized_tokens'] = df_test['vectorized_tokens'].apply(extract_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05fad1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.astype(preproc['change_type_columns'])\n",
    "df_test = df_test.astype(preproc['change_type_columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "498dc4ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5194c8dbc7654c1d833e5ba0dfd47a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    df_train[str(i)] = df_train['vectorized_tokens'].apply(lambda x: x[i])\n",
    "    df_test[str(i)] = df_test['vectorized_tokens'].apply(lambda x: x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53c5913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_vectors(target_vectors: np.ndarray, vector_space: np.ndarray, \n",
    "                         k: int =5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Find the k vectors in the given vector_space that are closest to the given target_vectors.\n",
    "\n",
    "    Args:\n",
    "        target_vectors (numpy.ndarray): A 2D numpy array of shape (n, m) \n",
    "            where n is the number of target vectors and m is the dimensionality of the vectors.\n",
    "        vector_space (numpy.ndarray): A 2D numpy array of shape (p, m) \n",
    "            where p is the number of vectors in the vector space and m is the \n",
    "            dimensionality of the vectors.\n",
    "        k (int): The number of closest vectors to return. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 1D numpy array of length k containing the indices of \n",
    "        the closest vectors in the vector space.\n",
    "    \"\"\"\n",
    "    sum_distances = []\n",
    "    \n",
    "    \n",
    "    mms = MinMaxScaler()\n",
    "    \n",
    "    \n",
    "    #Нормализуем векторы\n",
    "    target_vectors = mms.fit_transform(target_vectors)\n",
    "    vector_space = mms.transform(vector_space)\n",
    "    \n",
    "    \n",
    "    for vector in vector_space:\n",
    "        # создаем массив расстояний между вектором в пространстве и целевыми векторами\n",
    "        distances = np.linalg.norm(target_vectors - vector, axis=1)\n",
    "        # сохраняем сумму расстояний между вектором в пространстве и целевыми векторами\n",
    "        sum_distances.append(np.sum(distances))\n",
    "    \n",
    "    \n",
    "    # выбираем набор векторов с минимальной суммой расстояний до каждого вектора в target_vectors\n",
    "    if k >= vector_space.shape[0]:\n",
    "        return np.nonzero(vector_space)\n",
    "    \n",
    "    \n",
    "    return np.argpartition(sum_distances, k)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a103d63",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def baseline_lgbm(df_tr: pd.DataFrame, df_t: pd.DataFrame, params = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Trains a LightGBM classifier on the training set and returns the score on the test set.\n",
    "\n",
    "    Args:\n",
    "        df_tr (pandas.DataFrame): A pandas DataFrame containing the training set.\n",
    "        df_t (pandas.DataFrame): A pandas DataFrame containing the test set.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The score on the test set.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x_train = df_tr[df_tr.columns[:-1]]\n",
    "    y_train = df_tr['target']\n",
    "    \n",
    "    x_test = df_t[df_tr.columns[:-1]]\n",
    "    y_test = df_t['target']\n",
    "    \n",
    "\n",
    "    model = LGBMClassifier(random_state=RAND, class_weight='balanced', n_jobs=-1)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_score = model.predict_proba(x_test)\n",
    "\n",
    "    return get_metrics(y_test, y_pred, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e54c5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df_train, df_sup, sup):\n",
    "    unique_reg_okpd = df_train[df_train['supplier'] == sup]['reg_code'].unique()\n",
    "    \n",
    "    # фильтруем train и test на основе уникальных reg_code поставщиков \n",
    "    df_sup_train = df_train[df_train['reg_code'].isin(unique_reg_okpd)]\n",
    "    df_sup_test = df_test[df_test['reg_code'].isin(unique_reg_okpd)]\n",
    "    \n",
    "    if df_sup_test.empty:\n",
    "        df_sup_test = df_test\n",
    "        \n",
    "    return df_sup_train, df_sup_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e83fcea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_data(df_train: pd.DataFrame, df_test: pd.DataFrame, \n",
    "              df: pd.DataFrame, sup: int) -> Tuple[pd.DataFrame, pd.DataFrame, Set]:\n",
    "    \"\"\"\n",
    "    The function filters the training and test datasets of a supplier with a given \n",
    "    reg_code and returns the filtered dataframes as well as the set of participations \n",
    "    of this supplier in the original dataset.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        df_train: pandas.DataFrame - the training dataset\n",
    "        df_test: pandas.DataFrame - the test dataset\n",
    "        df: pandas.DataFrame - the original dataset\n",
    "        sup: str - the registration code of the supplier\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        Tuple[pandas.DataFrame, pandas.DataFrame, set] - a tuple of the filtered \n",
    "        dataframes of the training and test datasets, as well as the set of participations \n",
    "        of the supplier.\n",
    "    \"\"\"\n",
    "    unique_reg_okpd = df_train[df_train['supplier'] == sup]['reg_code'].unique()\n",
    "    \n",
    "    # фильтруем train и test на основе уникальных reg_code поставщиков \n",
    "    df_sup_train = df_train[df_train['reg_code'].isin(unique_reg_okpd)]\n",
    "    df_sup_test = df_test[df_test['reg_code'].isin(unique_reg_okpd)]\n",
    "    \n",
    "    # выделяем все участия поставщика\n",
    "    df_sup_true = set(df[df['supplier'] == sup]['purchase'])\n",
    "    \n",
    "    # проверяем, остались ли участия на test после фильтрации\n",
    "    if df_sup_test['purchase'].isin(df_sup_true).nunique() < 2:\n",
    "        df_sup_test = df_test.copy()\n",
    "        \n",
    "    # удаляем выделенные столбцы и дубликаты\n",
    "    df_sup_train = df_sup_train.drop(columns=columns_to_drop).drop_duplicates()\n",
    "    df_sup_test = df_sup_test.drop(columns=columns_to_drop).drop_duplicates()\n",
    "    \n",
    "    df_sup_test = df_sup_test.set_index('purchase')\n",
    "    df_sup_train = df_sup_train.set_index('purchase')\n",
    "    \n",
    "    return df_sup_train, df_sup_test, df_sup_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0136e253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rec_algorithm(df_train: pd.DataFrame, df_test: pd.DataFrame, \n",
    "                  df_submission: pd.DataFrame, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recommends items for the first 500 suppliers in df_submission based on \n",
    "    training data in df_train and df.\n",
    "    Uses the LightGBM classifier and the baseline_lgbm function to make predictions.\n",
    "\n",
    "    Args:\n",
    "    - df_train (pd.DataFrame): Training data with columns 'purchase', 'supplier', 'reg_code', and 'target'.\n",
    "    - df_test (pd.DataFrame): Test data with columns 'purchase', 'supplier', 'reg_code'.\n",
    "    - df_submission (pd.DataFrame): Dataframe with the first 500 suppliers for which to recommend items.\n",
    "    - df (pd.DataFrame): Dataframe with columns 'purchase', 'supplier', 'reg_code'.\n",
    "\n",
    "    Returns:\n",
    "    - metrics (pd.DataFrame): Mean of the ROC AUC score for each supplier in \n",
    "    df_submission after running the baseline_lgbm function.\n",
    "    \"\"\"\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    for sup in tqdm(df_submission.index[:500]):\n",
    "\n",
    "        # подготавливаем данные к обучению\n",
    "        df_sup_train, df_sup_test, df_sup_true = edit_data(df_train, df_test, df, sup)\n",
    "\n",
    "        # добавляем метки для обучения алгоритма классификации \n",
    "        df_sup_train['target'] = df_sup_train.index.isin(df_sup_true).astype(int)\n",
    "        df_sup_test['target'] = df_sup_test.index.isin(df_sup_true).astype(int)\n",
    "\n",
    "        metrics = pd.concat([metrics, baseline_lgbm(df_sup_train, df_sup_test)])\n",
    "\n",
    "    return metrics.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa50e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg_nearest(df_train: pd.DataFrame, df_test: pd.DataFrame, \n",
    "                df_submission_less_4: pd.DataFrame, df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Computes the average recall score for the top 500 rows of df_submission_less_4 \n",
    "    using the nearest neighbor algorithm.\n",
    "\n",
    "    Args:\n",
    "    - df_train: training data DataFrame\n",
    "    - df_test: testing data DataFrame\n",
    "    - df_submission_less_4: submission data DataFrame with purchase information\n",
    "    - df: DataFrame containing information about the suppliers\n",
    "\n",
    "    Returns:\n",
    "    - float: the average recall score for the top 500 rows of df_submission_less_4\n",
    "    \"\"\"\n",
    "\n",
    "    recall_less_4 = []\n",
    "\n",
    "    for sup in tqdm(df_submission_less_4.index[:500]):\n",
    "        # подготавливаем данные к обучению\n",
    "        df_sup_train, df_sup_test, df_sup_true = edit_data(df_train, df_test, df, sup)\n",
    "\n",
    "        # выделяем векторы участия поставщика на train\n",
    "        vectors = df_sup_train[df_sup_train.index.isin(df_sup_true)]\n",
    "\n",
    "        # определяем векторы наиболее близки для поставщика на test\n",
    "        idx = find_closest_vectors(vectors, df_sup_test)\n",
    "        y_pred = set(df_sup_test.iloc[idx].index)\n",
    "\n",
    "        recall = len(y_pred & df_submission_less_4.loc[sup]['purchases']) \\\n",
    "                 / len(df_submission_less_4.loc[sup]['purchases'])\n",
    "\n",
    "        recall_less_4.append(recall)\n",
    "\n",
    "    return (np.mean(recall_less_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame()\n",
    "\n",
    "for sup in tqdm(df_submission.index[:500]):\n",
    "\n",
    "    # подготавливаем данные к обучению\n",
    "    df_sup_train, df_sup_test, df_sup_true = edit_data(df_train, df_test, df, sup)\n",
    "\n",
    "    # добавляем метки для обучения алгоритма классификации \n",
    "    df_sup_train['target'] = df_sup_train.index.isin(df_sup_true).astype(int)\n",
    "    df_sup_test['target'] = df_sup_test.index.isin(df_sup_true).astype(int)\n",
    "\n",
    "    metrics = pd.concat([metrics, baseline_lgbm(df_sup_train, df_sup_test)])\n",
    "\n",
    "return metrics.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a513ff04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63715bd31d674de18fa793db2839f19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19588/1381042027.py:15: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  return metrics.mean(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy     0.956422\n",
       "ROC_AUC      0.841957\n",
       "Precision    0.241158\n",
       "Recall       0.266748\n",
       "f1           0.219859\n",
       "Logloss      0.196172\n",
       "dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_algorithm(df_train, df_test, df_submission, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2bb87c55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6904e1b41a415aab8d584fe2149012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.3411196863246043"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_nearest(df_train, df_test, df_submission_less_4, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42feff9c",
   "metadata": {},
   "source": [
    "# Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b938dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial, x: pd.DataFrame, y: pd.Series, learning_rate=None) -> float:\n",
    "    \"\"\"\n",
    "    This function defines the objective function for an Optuna study to tune hyperparameters\n",
    "    for a LightGBM binary classification model. \n",
    "\n",
    "    Args:\n",
    "        trial (optuna.Trial): A trial corresponding to a set of hyperparameters.\n",
    "        x (pd.DataFrame): The features to be used for training and validation.\n",
    "        y (pd.Series): The target variable for training and validation.\n",
    "\n",
    "    Returns:\n",
    "        float: The mean of the cross-validation AUC-ROC scores for the given set of hyperparameters.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [400]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "#         'learning_rate': trial.suggest_categorical('learning_rate', [learning_rate]),\n",
    "#         'max_bin': trial.suggest_int('max_bin', 200, 800),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 200, 20000, step=200),\n",
    "#         'lambda_l1': trial.suggest_int('lambda_l1', 0, 50),\n",
    "#         'lambda_l2': trial.suggest_int('lambda_l2', 0, 50),\n",
    "#         'min_split_gain': trial.suggest_float('min_split_gain', 0.001, 0.1),\n",
    "#         'objective': 'binary',\n",
    "#         'metric': 'auc',\n",
    "#         'feature_fraction': trial.suggest_float('feature_fraction', 0.3, 1.0),\n",
    "#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.3, 1.0),\n",
    "#         'bagging_freq': trial.suggest_int('bagging_freq', 2, 6),\n",
    "#         'random_state': RAND,\n",
    "    }\n",
    "\n",
    "    cv_pred = np.empty(N_FOLDS)\n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(x, y)):\n",
    "        x_train_, x_val_ = x.iloc[train_idx], x.iloc[test_idx]\n",
    "        y_train_, y_val_ = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        pruning = optuna.integration.LightGBMPruningCallback(trial, 'auc')\n",
    "\n",
    "        model = LGBMClassifier(\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "            **params\n",
    "        )\n",
    "        model.fit(x_train_, y_train_,\n",
    "                  eval_metric='auc',\n",
    "                  eval_set=[(x_val_, y_val_)],\n",
    "                  early_stopping_rounds=100,\n",
    "                  callbacks=[pruning],\n",
    "                  verbose=0)\n",
    "\n",
    "        y_pred = model.predict(x_val_)\n",
    "        y_proba = model.predict_proba(x_val_)[:, 1]\n",
    "\n",
    "        cv_pred[fold] = roc_auc_score(y_val_, y_proba)\n",
    "    return (np.mean(cv_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02067b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lgbm(df_tr: pd.DataFrame, df_t: pd.DataFrame, learning_rate=None) -> pd.DataFrame:\n",
    "    \n",
    "    x_train = df_tr[df_tr.columns[:-1]]\n",
    "    y_train = df_tr['target']\n",
    "    \n",
    "    x_test = df_t[df_tr.columns[:-1]]\n",
    "    y_test = df_t['target']\n",
    "     \n",
    "        \n",
    "    func = lambda trial: objective(trial, x_train, y_train, learning_rate)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(func, n_trials=50, n_jobs=-1)\n",
    "    \n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a07d0f1d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "    \n",
    "def save_file(file_path, data):       \n",
    "    with open(file_path, 'w') as file:\n",
    "        yaml.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52318d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_algorithm(df_train: pd.DataFrame, df_test: pd.DataFrame, \n",
    "                   df_submission: pd.DataFrame, df: pd.DataFrame, sup, learning_rate=None):\n",
    "    \n",
    "    # подготавливаем данные к обучению\n",
    "    df_sup_train, df_sup_test, df_sup_true = edit_data(df_train, df_test, df, sup)\n",
    "\n",
    "    # добавляем метки для обучения алгоритма классификации \n",
    "    df_sup_train['target'] = df_sup_train.index.isin(df_sup_true).astype(int)\n",
    "    df_sup_test['target'] = df_sup_test.index.isin(df_sup_true).astype(int)\n",
    "\n",
    "    params = tune_lgbm(df_sup_train, df_sup_test, sup, learning_rate)\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d103dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../config/model_params.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e84c2b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe1756de3df4c66a6dba71aba1055bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6751165316026022, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6751165316026022\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4683249767096229, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4683249767096229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5035541546690397, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5035541546690397\n",
      "[LightGBM] [Warning] feature_fraction is set=0.535969077444137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.535969077444137\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=26, reg_lambda=0.0 will be ignored. Current value: lambda_l2=26\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7941652261682852, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7941652261682852\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5451781611003428, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5451781611003428\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8431536617748157, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8431536617748157\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7182420454626154, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7182420454626154\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=41, reg_lambda=0.0 will be ignored. Current value: lambda_l2=41\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4026079456109417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4026079456109417\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9871964898459165, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9871964898459165\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] lambda_l1 is set=36, reg_alpha=0.0 will be ignored. Current value: lambda_l1=36\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6920323854263122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6920323854263122\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3616062238831329, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3616062238831329\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=23, reg_lambda=0.0 will be ignored. Current value: lambda_l2=23\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3444626033187826, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3444626033187826\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4414634761234264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4414634761234264\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6499770827257711, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6499770827257711\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7062872452151088, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7062872452151088\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6751165316026022, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6751165316026022\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4683249767096229, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4683249767096229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4026079456109417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4026079456109417\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9871964898459165, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9871964898459165\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5035541546690397, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5035541546690397\n",
      "[LightGBM] [Warning] feature_fraction is set=0.535969077444137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.535969077444137\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=26, reg_lambda=0.0 will be ignored. Current value: lambda_l2=26\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8431536617748157, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8431536617748157\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7182420454626154, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7182420454626154\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=41, reg_lambda=0.0 will be ignored. Current value: lambda_l2=41\n",
      "[LightGBM] [Warning] lambda_l1 is set=36, reg_alpha=0.0 will be ignored. Current value: lambda_l1=36\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6920323854263122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6920323854263122\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3616062238831329, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3616062238831329\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=23, reg_lambda=0.0 will be ignored. Current value: lambda_l2=23\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7941652261682852, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7941652261682852\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5451781611003428, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5451781611003428\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6499770827257711, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6499770827257711\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7062872452151088, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7062872452151088\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3444626033187826, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3444626033187826\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4414634761234264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4414634761234264\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=36, reg_alpha=0.0 will be ignored. Current value: lambda_l1=36\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6920323854263122, subsample=1.0 will be ignored. Current value: bagging_fraction"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 14658 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = open_file(file_path)\n",
    "\n",
    "for sup in tqdm(df_submission.index[:500]):\n",
    "\n",
    "    if sup in data:\n",
    "        params = tune_algorithm(df_train, df_test, df_submission, df, sup, **data[sup])\n",
    "        data[sup].extend(params)\n",
    "        \n",
    "    # Если ключа еще нет, создать новый список\n",
    "    else:\n",
    "        params = tune_algorithm(df_train, df_test, df_submission, df, sup)        \n",
    "        data[sup] = params\n",
    "\n",
    "save_file(file_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "040e9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_lgbm(df_tr: pd.DataFrame, df_t: pd.DataFrame, params = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Trains a LightGBM classifier on the training set and returns the score on the test set.\n",
    "\n",
    "    Args:\n",
    "        df_tr (pandas.DataFrame): A pandas DataFrame containing the training set.\n",
    "        df_t (pandas.DataFrame): A pandas DataFrame containing the test set.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The score on the test set.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x_train = df_tr[df_tr.columns[:-1]]\n",
    "    y_train = df_tr['target']\n",
    "    \n",
    "    x_test = df_t[df_tr.columns[:-1]]\n",
    "    y_test = df_t['target']\n",
    "    \n",
    "\n",
    "    model = LGBMClassifier(class_weight='balanced', n_jobs=-1, **params)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_score = model.predict_proba(x_test)\n",
    "\n",
    "    return get_metrics(y_test, y_pred, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75d6c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba5f697a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7b238c66414832a44283ad9ddaed40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=36, reg_alpha=0.0 will be ignored. Current value: lambda_l1=36\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6920323854263122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6920323854263122\n",
      "[LightGBM] [Warning] lambda_l2 is set=23, reg_lambda=0.0 will be ignored. Current value: lambda_l2=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3616062238831329, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3616062238831329\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5560994109885059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5560994109885059\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.614311629103369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.614311629103369\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4178358745006348, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4178358745006348\n",
      "[LightGBM] [Warning] lambda_l2 is set=41, reg_lambda=0.0 will be ignored. Current value: lambda_l2=41\n",
      "[LightGBM] [Warning] feature_fraction is set=0.40786498865682796, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.40786498865682796\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9862971741993876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9862971741993876\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5736238903233125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5736238903233125\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.32919183194707496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.32919183194707496\n",
      "[LightGBM] [Warning] lambda_l2 is set=17, reg_lambda=0.0 will be ignored. Current value: lambda_l2=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9686597284526643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9686597284526643\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=41, reg_alpha=0.0 will be ignored. Current value: lambda_l1=41\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8943942387901136, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8943942387901136\n",
      "[LightGBM] [Warning] lambda_l2 is set=28, reg_lambda=0.0 will be ignored. Current value: lambda_l2=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8537870281046971, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8537870281046971\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=32, reg_alpha=0.0 will be ignored. Current value: lambda_l1=32\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6881558989580775, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6881558989580775\n",
      "[LightGBM] [Warning] lambda_l2 is set=21, reg_lambda=0.0 will be ignored. Current value: lambda_l2=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4574788708934798, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4574788708934798\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=46, reg_alpha=0.0 will be ignored. Current value: lambda_l1=46\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9470306861265018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9470306861265018\n",
      "[LightGBM] [Warning] lambda_l2 is set=36, reg_lambda=0.0 will be ignored. Current value: lambda_l2=36\n",
      "[LightGBM] [Warning] feature_fraction is set=0.34259198017564885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.34259198017564885\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=43, reg_alpha=0.0 will be ignored. Current value: lambda_l1=43\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8481563761844368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8481563761844368\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.31957952123349637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.31957952123349637\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=33, reg_alpha=0.0 will be ignored. Current value: lambda_l1=33\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46834370165631634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46834370165631634\n",
      "[LightGBM] [Warning] lambda_l2 is set=46, reg_lambda=0.0 will be ignored. Current value: lambda_l2=46\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8773471306677978, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8773471306677978\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8696092930828663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8696092930828663\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5387112450468083, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5387112450468083\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=18, reg_alpha=0.0 will be ignored. Current value: lambda_l1=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6369207937285443, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6369207937285443\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9393046392849205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9393046392849205\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=34, reg_alpha=0.0 will be ignored. Current value: lambda_l1=34\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7879045848783324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7879045848783324\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.717258277008782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717258277008782\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6013496554358119, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6013496554358119\n",
      "[LightGBM] [Warning] lambda_l2 is set=43, reg_lambda=0.0 will be ignored. Current value: lambda_l2=43\n",
      "[LightGBM] [Warning] feature_fraction is set=0.48092170022268554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48092170022268554\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44222680312989393, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44222680312989393\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.931552869556695, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.931552869556695\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9917167081050979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9917167081050979\n",
      "[LightGBM] [Warning] lambda_l2 is set=42, reg_lambda=0.0 will be ignored. Current value: lambda_l2=42\n",
      "[LightGBM] [Warning] feature_fraction is set=0.930922844353473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.930922844353473\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=27, reg_alpha=0.0 will be ignored. Current value: lambda_l1=27\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4979757296260174, subsample=1.0 will be ignored. Current value: "
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 10400 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.DataFrame()\n",
    "\n",
    "for sup in tqdm(df_submission.index[:500]):\n",
    "\n",
    "    # подготавливаем данные к обучению\n",
    "    df_sup_train, df_sup_test, df_sup_true = edit_data(df_train, df_test, df, sup)\n",
    "\n",
    "    # добавляем метки для обучения алгоритма классификации \n",
    "    df_sup_train['target'] = df_sup_train.index.isin(df_sup_true).astype(int)\n",
    "    df_sup_test['target'] = df_sup_test.index.isin(df_sup_true).astype(int)\n",
    "    \n",
    "    params = data[sup]\n",
    "\n",
    "    metrics = pd.concat([metrics, classifier_lgbm(df_sup_train, df_sup_test, params=params)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b372630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.730974\n",
       "ROC_AUC      0.743162\n",
       "Precision    0.090660\n",
       "Recall       0.638708\n",
       "f1           0.139746\n",
       "Logloss      0.436611\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac527c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
